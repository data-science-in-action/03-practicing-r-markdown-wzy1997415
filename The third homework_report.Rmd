---
title: "Approximation of the Distribution"
author: "王昭元"
date: "2020/3/25"
geometry: left = 3.18cm, right = 3.18cm, top = 2.0cm, bottom = 2.0cm
output:
  pdf_document: 
    latex_engine: xelatex
  html_document:
    df_print: paged
fontsize: 12pt
keywords: Monte Carlo, box plots，R Markdown
papersize: letter
documentclass: article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

This report fits the standard normal distribution by the Monte Carlo methods and compare the approximation of the distribution under different ‘t’ and ‘n’ values.

# Introduction {#sec:intro}

  This report fits approximation of the distribution fuction of $N(0,1)$ by the Monte Carlo methods,including three parts.
  
  The first part, the truth value of each 't' value is calculated according to the cumulative density function of the standard normal distribution. 
 
  Secondly, the fitting degree of monte carlo method is compared under different 't' and 'n' values. the definite integral in the experiment with the approval at $n \in \{10^2, 10^3, 10^4\}$ at $t \in \{0.0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72\}$ to form a table. 
 
  Finally, repeat the experiment 100 times and draw box plots of the 100
approximation errors at each $t$ for
each $n$.

# Math Equations

  To solve this problem, I consider approximation the distribution
function of  $N(0,1)$ , 
\begin{equation}
\Phi(t) = \int_{-\infty}^t \frac{1}{\sqrt{2\pi}} e^{-y^2 / 2} d y,
(\#eq:cdf)
  \end{equation}
by the Monte Carlo methods:
\begin{equation}
\hat\Phi(t) = \frac{1}{n} \sum_{i=1}^n I(X_i \le t),
  \end{equation}
where $X_i$'s are a random sample from $N(0, 1)$, and $I(\cdot)$ is
the indicator function. 

# Table

  I experiment with the approximation at $n \in \lbrace10^2,10^3,10^4\rbrace$ 
at 

$t \in \lbrace0.0,0.67,0.84,1.28,1.65,2.32,2.58,3.09,3.72\rbrace$
to form a table. The resulting table is shown in table \@ref(tab:norm). 

(ref:norm) The table of approximation results.

```{r norm, echo = TRUE }
n=c(100,1000,10000)
t=c(0,0.67,0.84,1.28,1.65,2.32,2.58,3.09,3.72)
p=matrix(0,nrow=3,ncol=9)
#a=0
for (i in 1:3)
  for(j in 1:9){
    num=rnorm(n[i],0,1)
    p[i,j]=mean(num<t[j])
  }
rownames(p)<-n
colnames(p)<-t
real_p<-c(pnorm(0),pnorm(0.67),pnorm(0.84),pnorm(1.28),pnorm(1.65),
          pnorm(2.32),pnorm(2.58),pnorm(3.09),pnorm(3.72))
p<-rbind(p,real_p)
p<-round(p,digits=3)

library(knitr)
library(magrittr)
library(kableExtra)
kable(p, booktabs=TRUE, caption='(ref:norm)') %>%
  kable_styling(bootstrap_options = "striped",full_width = F) %>% 
 column_spec(1,bold=T)

```

# The Boxplots of Errors

  Further, repeat the experiment 100 times. Draw box plots of the 100
approximation errors at each $t$ using **ggplot2** for
each $n$. 

(ref:cap-error) The boxplots of errors

```{r, echo = FALSE }  
p_repeat=array(0,dim=c(3,9,100))  
for (i in 1:3)
  for(j in 1:9)
    for (k in 1:100){
      num=rnorm(n[i],0,1)
      p_repeat[i,j,k]=mean(num<t[j])
    }
dimnames(p_repeat)[[1]]<-n
dimnames(p_repeat)[[2]]<-t

V1<-c(1:100)
needdata<-data.frame(V1)
k=0
for (i in 1:3)
  for (j in 1:9){
    k=k+1
    print(k)
    needdata[ ,k]<-p_repeat[i,j, ]
    needdata[ ,k]<-needdata[ ,k]-pnorm(t[j])
  }
check<-data.frame(check1<-c("0-100"),check2<-c("0.67-100"),check3<-c("0.84-100"),check4<-c("1.28-100"),check5<-c("1.65-100"),check6<-c("2.32-100"),check7<-c("2.58-100"),check8<-c("3.09-100"),check9<-c("3.72-100"),
                  check10<-c("0-1000"),check11<-c("0.67-1000"),check12<-c("0.84-1000"),check13<-c("1.28-1000"),check14<-c("1.65-1000"),check15<-c("2.32-1000"),check16<-c("2.58-1000"),check17<-c("3.09-1000"),check18<-c("3.72-1000"),
                  check19<-c("0-10000"),check20<-c("0.67-10000"),label21<-c("0.84-10000"),check22<-c("1.28-10000"),check23<-c("1.65-10000"),check24<-c("2.32-10000"),check25<-c("2.58-10000"),check26<-c("3.09-10000"),check27<-c("3.72-10000"))
library(ggplot2)
library(lattice)
library(plyr)
library(Rmisc)

p1<-ggplot(data=needdata,aes(y=V1,x=check1))+geom_boxplot(
  fill="thistle",colour="gray27")+
  labs(title="Boxplot of error at t=0, n=100",y="error",
       x=NULL)+theme(plot.title=element_text(size=13,hjust=0.5))

p10<-ggplot(data=needdata,aes(y=V10,x=check10))+geom_boxplot(
  fill="thistle",colour="gray27")+
  labs(title="Boxplot of error at t=0, n=1000",y="error",
       x=NULL)+theme(plot.title=element_text(size=13,hjust=0.5))

p19<-ggplot(data=needdata,aes(y=V19,x=check19))+geom_boxplot(
  fill="thistle",colour="gray27")+
  labs(title="Boxplot of error at t=0, n=10000",y="error",
       x=NULL)+theme(plot.title=element_text(size=13,hjust=0.5))
g1<-multiplot(p1,p10,p19,cols=3)


p1<-ggplot(data=needdata,aes(y=V1,x=check1))+geom_boxplot(
  fill="thistle",colour="gray27")+
  labs(title="Boxplot of error at t=0, n=100",y="error",
       x=NULL)+theme(plot.title=element_text(size=13,hjust=0.5))

p5<-ggplot(data=needdata,aes(y=V5,x=check5))+geom_boxplot(
  fill="thistle",colour="gray27")+
  labs(title="Boxplot of error at t=1.65, n=100",y="error",
       x=NULL)+theme(plot.title=element_text(size=13,hjust=0.5))

p9<-ggplot(data=needdata,aes(y=V9,x=check9))+geom_boxplot(
  fill="thistle",colour="gray27")+
  labs(title="Boxplot of error at t=3.72, n=100",y="error",
       x=NULL)+theme(plot.title=element_text(size=13,hjust=0.5))
g2<-multiplot(p1,p5,p9,cols=3)


```





# Conclusion 

  From the table and boxplots of errors,we can conclude that as n gets bigger and bigger,approximation of the distribution function is getting closer and closer to the truth value.


# R Code Reference

  Refer to the code of other classmates in the process of compiling the code.
  [Reference website：https://github.com/data-science-in-action/03-practicing-r-markdown-fanngguofang]

  Finally,I would like to thank teachers and classmates.Through this course, I learned lots of skills and knowledge.